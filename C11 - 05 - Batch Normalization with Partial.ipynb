{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all these layers, we have to pass the same arguments over and over again. One way to approach this is to take advantage of the Python function partial. Partial basically allows you to specify a set of parameters to use for a function every time. You can leave other parameters unspecified and pass them on call. Here's an example that adds 5 numbers together. Suppose we want to call this function many times with 4 known values and 1 that changes at every call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def addbunch(a, b, c, d, e):\n",
    "    return a+b+c+d+e\n",
    "\n",
    "addbunch(1, 2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "addbunchmod = partial(addbunch, b=2, c=3, d=4, e=5)\n",
    "print(addbunchmod(1))\n",
    "print(addbunchmod(2))\n",
    "print(addbunchmod(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we called the new function `addbunchmod` it had default values for b, c, d, and e. \n",
    "\n",
    "We can use this to streamline the previous notebook's Batch Normalization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    # using partial to make layer functions that have repetitive parameters set\n",
    "    my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=batch_norm_momentum)\n",
    "    my_dense_layer = partial(tf.layers.dense, kernel_initializer=he_init)\n",
    "    \n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y , 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train acc: 0.914236 val acc: 0.9192\n",
      "5 train acc: 0.972 val acc: 0.9666\n",
      "10 train acc: 0.984836 val acc: 0.9744\n",
      "15 train acc: 0.990818 val acc: 0.9788\n",
      "20 train acc: 0.993927 val acc: 0.9802\n",
      "25 train acc: 0.995945 val acc: 0.9806\n",
      "30 train acc: 0.996909 val acc: 0.9806\n",
      "35 train acc: 0.998236 val acc: 0.9792\n",
      "39 train acc: 0.998655 val acc: 0.9834\n",
      "Test acc: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# execution\n",
    "\n",
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops], feed_dict={training: True, X:X_batch, y:y_batch})\n",
    "        if epoch % 5 == 0 or epoch == n_epochs - 1:\n",
    "            acc_train = accuracy.eval(feed_dict={X:mnist.train.images, y:mnist.train.labels})\n",
    "            acc_val = accuracy.eval(feed_dict={X:mnist.validation.images, y:mnist.validation.labels})\n",
    "            print(epoch, \"train acc:\", acc_train, \"val acc:\", acc_val)\n",
    "    acc_test = accuracy.eval(feed_dict={X:mnist.test.images, y:mnist.test.labels})\n",
    "    print(\"Test acc:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
